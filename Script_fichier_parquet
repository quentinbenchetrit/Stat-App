#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import argparse
import logging
import os
import sys
from pathlib import Path
import duckdb

LOG = logging.getLogger("merge_patents_ep7")

DEFAULT_BASE = "/home/onyxia/work/Projet stat"
DEFAULT_CSV = str(Path(DEFAULT_BASE) / "list_cpc_patent_EP.csv")
DEFAULT_TXT = str(Path(DEFAULT_BASE) / "202401_EPO_App_reg.txt")
DEFAULT_OUT = str(Path(DEFAULT_BASE) / "patents_merged.parquet")
DEFAULT_DB  = str(Path(DEFAULT_BASE) / "work.duckdb")

def parse_args():
    p = argparse.ArgumentParser(
        description="Merge EP CSV (CPC4) and TXT (applicants) using a strict 7-digit EP key."
    )
    p.add_argument("--csv", default=DEFAULT_CSV, help="Path to CSV (list_cpc_patent_EP.csv)")
    p.add_argument("--txt", default=DEFAULT_TXT, help="Path to TXT (202401_EPO_App_reg.txt, '|' delimited)")
    p.add_argument("--out", default=DEFAULT_OUT, help="Output Parquet path")
    p.add_argument("--duckdb", default=DEFAULT_DB, help="DuckDB database file (for spill/caching)")
    p.add_argument("--threads", type=int, default=os.cpu_count() or 4, help="DuckDB threads")
    return p.parse_args()

def fail(msg: str):
    LOG.error(msg)
    sys.exit(1)

def main():
    args = parse_args()
    logging.basicConfig(level=logging.INFO, format="%(asctime)s | %(levelname)s | %(message)s")

    csv_path = Path(args.csv)
    txt_path = Path(args.txt)
    out_path = Path(args.out)

    if not csv_path.is_file():
        fail(f"CSV not found: {csv_path}")
    if not txt_path.is_file():
        fail(f"TXT not found: {txt_path}")
    out_path.parent.mkdir(parents=True, exist_ok=True)

    con = duckdb.connect(database=str(args.duckdb) if args.duckdb else ":memory:")
    con.execute(f"PRAGMA threads={args.threads}")
    con.execute("PRAGMA preserve_insertion_order=false")

    # 1) Charger les fichiers bruts
    con.execute(f"""
        CREATE OR REPLACE VIEW csv_raw AS
        SELECT * FROM read_csv_auto(
            '{csv_path.as_posix()}',
            SAMPLE_SIZE=-1,
            HEADER=TRUE
        );
    """)

    con.execute(f"""
        CREATE OR REPLACE VIEW txt_raw AS
        SELECT * FROM read_csv_auto(
            '{txt_path.as_posix()}',
            DELIM='|',
            QUOTE='\"',
            SAMPLE_SIZE=-1,
            HEADER=TRUE
        );
    """)

    # 2) Vérifier les colonnes attendues
    csv_cols = {c[0] for c in con.execute("SELECT * FROM csv_raw LIMIT 0").description}
    txt_cols = {c[0] for c in con.execute("SELECT * FROM txt_raw LIMIT 0").description}

    need_csv = {"publication_number", "publication_date", "CPC4"}
    need_txt = {
        "app_nbr", "appln_id", "pub_nbr", "person_id", "app_name", "address", "city",
        "postal_code", "reg_code", "ctry_code", "reg_share", "app_share"
    }

    if not need_csv.issubset(csv_cols):
        fail(f"CSV missing columns. Found={sorted(csv_cols)} Needed>={sorted(need_csv)}")
    if not need_txt.issubset(txt_cols):
        fail(f"TXT missing columns. Found={sorted(txt_cols)} Needed>={sorted(need_txt)}")

    # 3) Comptages bruts
    csv_rows = con.execute("SELECT COUNT(*) FROM csv_raw").fetchone()[0]
    txt_rows = con.execute("SELECT COUNT(*) FROM txt_raw").fetchone()[0]
    LOG.info(f"CSV rows: {csv_rows:,} | TXT rows: {txt_rows:,}")

    # 4) Côté CSV : extraire STRICTEMENT 7 chiffres entre 'EP-' et '-<Lettre><Chiffre>'
    con.execute("""
        CREATE OR REPLACE VIEW csv_keyed AS
        SELECT
            -- doc7 : exactement 7 chiffres capturés
            regexp_extract(publication_number, '^EP-0*([0-9]{7})-[A-Z][0-9]$', 1) AS doc7,
            -- IMPORTANT: garder la date telle quelle (string) pour éviter les NULL
            publication_date AS publication_date,
            upper(trim(CPC4)) AS cpc4
        FROM csv_raw;
    """)

    # 5) Nettoyage & agrégation des CPC (uniques) par doc7
    con.execute("""
        CREATE OR REPLACE VIEW csv_cpc AS
        WITH filtered AS (
            SELECT doc7, publication_date, cpc4
            FROM csv_keyed
            WHERE doc7 IS NOT NULL
              AND cpc4 IS NOT NULL AND cpc4 <> ''
        ),
        pub_agg AS (
            -- MIN() sur string suffit si format ISO (YYYY-MM-DD)
            SELECT doc7, min(publication_date) AS publication_date
            FROM filtered
            GROUP BY doc7
        ),
        cpc_distinct AS (
            SELECT DISTINCT doc7, cpc4
            FROM filtered
        )
        SELECT
            p.doc7,
            p.publication_date,
            list(cd.cpc4) AS cpc4_list
        FROM pub_agg p
        JOIN cpc_distinct cd USING (doc7)
        GROUP BY p.doc7, p.publication_date;
    """)

    csv_valid = con.execute("SELECT COUNT(*) FROM csv_cpc").fetchone()[0]
    LOG.info(f"CSV patents with 7-digit key & CPC: {csv_valid:,}")

    # 6) Côté TXT : construire doc7 depuis app_nbr
    con.execute("""
        CREATE OR REPLACE VIEW txt_keyed AS
        SELECT
            -- doc7 extrait depuis app_nbr nettoyé
            regexp_extract(
                upper(replace(trim(app_nbr), '\"', '')),
                '^EP[0-9]{4}([0-9]{7}).*$',
                1
            ) AS doc7,
            person_id, app_name, address, city, postal_code, reg_code,
            ctry_code, reg_share, app_share
        FROM txt_raw
        WHERE app_nbr IS NOT NULL AND trim(app_nbr) <> '';
    """)

    # 7) Agréger les applicants par doc7
    con.execute("""
        CREATE OR REPLACE VIEW applicants AS
        SELECT
            doc7,
            list(person_id)   AS person_id_list,
            list(app_name)    AS app_name_list,
            list(address)     AS address_list,
            list(city)        AS city_list,
            list(postal_code) AS postal_code_list,
            list(reg_code)    AS reg_code_list,
            list(ctry_code)   AS ctry_code_list,
            list(reg_share)   AS reg_share_list,
            list(app_share)   AS app_share_list,
            count(*)          AS num_applicants
        FROM txt_keyed
        WHERE doc7 IS NOT NULL
        GROUP BY doc7;
    """)

    txt_valid = con.execute("SELECT COUNT(*) FROM applicants").fetchone()[0]
    LOG.info(f"TXT applicants with 7-digit key (from app_nbr): {txt_valid:,}")

    # 8) Jointure sur doc7
    con.execute("""
        CREATE OR REPLACE VIEW final AS
        SELECT
            c.doc7,
            try_cast(c.doc7 AS BIGINT) AS doc_number,  -- clé numérique 7 chiffres optionnelle
            'EP-' || c.doc7 AS ep_doc,                 -- EP-xxxxxxx sans kind
            c.publication_date,                        -- maintenant non nulle si CSV est rempli
            c.cpc4_list,
            a.person_id_list,
            a.app_name_list,
            a.address_list,
            a.city_list,
            a.postal_code_list,
            a.reg_code_list,
            a.ctry_code_list,
            a.reg_share_list,
            a.app_share_list,
            a.num_applicants
        FROM csv_cpc c
        INNER JOIN applicants a USING (doc7)
        WHERE c.cpc4_list IS NOT NULL;
    """)

    matched = con.execute("""
        SELECT COUNT(*) FROM (
            SELECT doc7 FROM csv_cpc
            INTERSECT
            SELECT doc7 FROM applicants
        );
    """).fetchone()[0]
    final_count = con.execute("SELECT COUNT(*) FROM final").fetchone()[0]
    LOG.info(f"Matched on 7-digit key (intersection): {matched:,}")
    LOG.info(f"Final row count (CPC non-empty): {final_count:,}")

    # 9) Écriture Parquet
    LOG.info(f"Writing Parquet → {out_path}")
    con.execute(f"COPY final TO '{out_path.as_posix()}' (FORMAT PARQUET);")
    LOG.info("Done.")

if __name__ == "__main__":
    try:
        main()
    except duckdb.Error as e:
        fail(f"DuckDB error: {e}")
    except Exception as e:
        fail(f"Unexpected error: {e}")
